<!DOCTYPE html> <html> 	<head> 		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> 		<script type="text/javascript" src="./../../OneDrive_Web_js/J0909.js"></script> 		<script type="text/javascript" src="../reading/functions.js"></script> 		<link rel="stylesheet" href="../reading/layout.css"> 		<script> 			const d10 = [  							]; 		</script> 	</head> 	<body onload='f1();' onkeydown='f4()' oncontextmenu="return false" onselectstart="return false" oncopy="return false" oncut="return false" onpaste="return false" draggable="false" ondragstart="return false" ondrop="return false"> 		<div id = "container"> 			<div id = "titleBox"> 			</div> 			<div id = "navigationBox"> 			</div>  			<div id = "contentBox"> 				<h4>문제</h4> 				<pre style='white-space:normal;'>MLP 코드의 일부입니다 이를 해결하는 다음 프로그램의 실행상태를 확인하세요 </pre> 				 	   				<h4>프로그램 코드</h4> 				<pre>	import numpy as np
	
	# 시그모이드 함수
	def actf삭제(x):
		return 1/(1+np.exp(-x))
	
	# 시그모이드 함수의 미분값
	def actf_deriv삭제( x ):
		    return x*(1-x)
	    
	# XOR 연산을 위한 4행*2열의 입력 행렬
	# 마지막 열은 바이어스를 나타낸다. 
	X = np.array([[0,0,1], [0,1,1], [1,0,1], [1,1,1]])
	                
	# XOR 연산을 위한 4행*1열의 목표 행렬
	y = np.array([[0], [1], [1], [0]])
	
	np.random.seed(5)
	
	inputs = 3	# 입력층의 노드 개수
	hiddens = 6	# 은닉층의 노드 개수
	outputs = 1	# 출력층의 노드 개수
	
	# 가중치를 ?1.0에서 1.0 사이의 난수로 초기화한다.
	weight0삭제 = 2*np.random.random((inputs, hiddens))-1   
	weight1삭제 = 2*np.random.random((hiddens, outputs))-1  
	
	# 반복한다. 
	for i in range(10000):
	
	    # 순방향 계산
	    layer0삭제 = X				# 입력을 layer0에 대입한다. 
	    net1삭제 = np.dot( layer0, weight0 )	# 행렬의 곱을 계산한다. 
	    layer1삭제 = actf( net1 )		# 활성화 함수를 적용한다. 
	    layer1[:,-1] = 1.0      	#  마지막 열은 바이어스를 나타낸다. 1.0으로 만든다.
	    net2삭제 = np.dot( layer1, weight1 )	# 행렬의 곱을 계산한다. 
	    layer2삭제 = actf( net2 )		# 활성화 함수를 적용한다. 
	
	    # 출력층에서의 오차를 계산한다. 
	    layer2_error삭제 = layer2 - y
	        
	    # 출력층에서의 델타값을 계산한다. 
	    layer2_delta삭제 = layer2_error * actf_deriv( layer2 )
	
	    # 은닉층에서의 오차를 계산한다.
	    # 여기서 T는 행렬의 전치를 의미한다. 
	    # 역방향으로 오차를 전파할 때는 반대방향이므로 행렬이 전치되어야 한다. 
	    layer1_error삭제 = np.dot( layer2_delta, weight1.T )
	    
	    # 은닉층에서의 델타를 계산한다.
	    layer1_delta삭제 = layer1_error * actf_deriv( layer1 )
	
	    # 은닉층->출력층을 연결하는 가중치를 수정한다. 
	    weight1 += -0.2*np.dot( layer1.T, layer2_delta )
	
	    # 입력층->은닉층을 연결하는 가중치를 수정한다. 
	    weight0 += -0.2*np.dot( layer0.T, layer1_delta )
	print( layer2 )			# 현재 출력층의 값을 출력한다.
	</pre> 				<br>
<table border='1'></table> 			</div> 		</div> 	</body> </html> 
